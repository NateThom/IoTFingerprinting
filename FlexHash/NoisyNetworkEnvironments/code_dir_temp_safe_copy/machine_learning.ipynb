{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import gc\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import ensemble\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    cross_validate,\n",
    ")\n",
    "\n",
    "from statistics import mean\n",
    "import umap\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.ioff()\n",
    "# %matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import wandb\n",
    "# wandb.init(project=\"smart_attacker_same_lightbulb\", entity=\"unr-mpl\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def remove_class(class_name, dataset):\n",
    "    dataset = dataset[dataset[\"class\"] != class_name]\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "path_to_iot_noise_cleaned = \"/home/nthom/Documents/SmartRecon/Fingerprinting in Noisy Network Environments/data/noise/iot_noise/iot_noise_hashes_cleaned.csv\"\n",
    "path_to_iot_noise_uncleaned = \"/home/nthom/Documents/SmartRecon/Fingerprinting in Noisy Network Environments/data/noise/iot_noise/iot_noise_hashes_uncleaned.csv\"\n",
    "\n",
    "path_to_network_noise_cleaned = \"/home/nthom/Documents/SmartRecon/Fingerprinting in Noisy Network Environments/data/noise/network_noise/network_noise_hashes_cleaned.csv\"\n",
    "path_to_network_noise_uncleaned = \"/home/nthom/Documents/SmartRecon/Fingerprinting in Noisy Network Environments/data/noise/network_noise/network_noise_hashes_uncleaned.csv\"\n",
    "\n",
    "path_to_per_packet_cleaned_devices = \"/home/nthom/Documents/SmartRecon/Fingerprinting in Noisy Network Environments/data/per_packet_hashes/cleaned/per-packet-hashes-cleaned.csv\"\n",
    "path_to_per_packet_uncleaned_devices = \"/home/nthom/Documents/SmartRecon/Fingerprinting in Noisy Network Environments/data/per_packet_hashes/uncleaned/per-packet-hashes-uncleaned.csv\"\n",
    "\n",
    "path_to_per_packet_cleaned_categories = \"/home/nthom/Documents/SmartRecon/Fingerprinting in Noisy Network Environments/data/per_packet_hashes/cleaned/cleaned-categories.csv\"\n",
    "path_to_per_packet_uncleaned_categories = \"/home/nthom/Documents/SmartRecon/Fingerprinting in Noisy Network Environments/data/per_packet_hashes/uncleaned/uncleaned-categories.csv\"\n",
    "\n",
    "path_to_same_plug_cleaned_interaction = \"/home/nthom/Documents/SmartRecon/Fingerprinting in Noisy Network Environments/data/same_device/same_plug/same_plug_cleaned_interaction/\"\n",
    "path_to_same_plug_cleaned_no_interaction = \"/home/nthom/Documents/SmartRecon/Fingerprinting in Noisy Network Environments/data/same_device/same_plug/same_plug_cleaned_no_interaction/\"\n",
    "path_to_same_plug_uncleaned_interaction = \"/home/nthom/Documents/SmartRecon/Fingerprinting in Noisy Network Environments/data/same_device/same_plug/same_plug_uncleaned_interaction/\"\n",
    "path_to_same_plug_uncleaned_no_interaction = \"/home/nthom/Documents/SmartRecon/Fingerprinting in Noisy Network Environments/data/same_device/same_plug/same_plug_uncleaned_no_interaction/\"\n",
    "\n",
    "path_to_same_bulb_cleaned_interaction = \"/home/nthom/Documents/SmartRecon/Fingerprinting in Noisy Network Environments/data/same_device/same_lightbulb/same_lightbulb_cleaned_interaction/\"\n",
    "path_to_same_bulb_cleaned_no_interaction = \"/home/nthom/Documents/SmartRecon/Fingerprinting in Noisy Network Environments/data/same_device/same_lightbulb/same_lightbulb_cleaned_no_interaction/\"\n",
    "path_to_same_bulb_uncleaned_interaction = \"/home/nthom/Documents/SmartRecon/Fingerprinting in Noisy Network Environments/data/same_device/same_lightbulb/same_lightbulb_uncleaned_interaction/\"\n",
    "path_to_same_bulb_uncleaned_no_interaction = \"/home/nthom/Documents/SmartRecon/Fingerprinting in Noisy Network Environments/data/same_device/same_lightbulb/same_lightbulb_uncleaned_no_interaction/\"\n",
    "\n",
    "path_to_same_cam_cleaned_interaction = \"/home/nthom/Documents/SmartRecon/Fingerprinting in Noisy Network Environments/data/same_device/same_cam/same_cam_cleaned_interaction/\"\n",
    "path_to_same_cam_cleaned_no_interaction = \"/home/nthom/Documents/SmartRecon/Fingerprinting in Noisy Network Environments/data/same_device/same_cam/same_cam_cleaned_no_interaction/\"\n",
    "path_to_same_cam_uncleaned_interaction = \"/home/nthom/Documents/SmartRecon/Fingerprinting in Noisy Network Environments/data/same_device/same_cam/same_cam_uncleaned_interaction/\"\n",
    "path_to_same_cam_uncleaned_no_interaction = \"/home/nthom/Documents/SmartRecon/Fingerprinting in Noisy Network Environments/data/same_device/same_cam/same_cam_uncleaned_no_interaction/\"\n",
    "\n",
    "path_to_simhash = \"/home/nthom/Documents/SmartRecon/Fingerprinting in Noisy Network Environments/data/simhashes/\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def noise_generator(original_df, names, one_hundred_times=False):\n",
    "    num_samples_to_generate = len(original_df.index)\n",
    "    if one_hundred_times == True:\n",
    "        num_samples_to_generate *= 100\n",
    "    num_digits_in_hash = 32\n",
    "    label = \"other\"\n",
    "    random_list = []\n",
    "\n",
    "    for i in tqdm(range(num_samples_to_generate), desc=\"Generating random noise\"):\n",
    "        temp_random_hash = []\n",
    "        for j in range(num_digits_in_hash):\n",
    "            temp_random_hash.append(random.randint(0, 255))\n",
    "        temp_random_hash.append(label)\n",
    "        random_list.append(temp_random_hash)\n",
    "\n",
    "    output_list = np.concatenate(\n",
    "        (np.array(random_list), np.array(original_df.values.tolist())), axis=0\n",
    "    ).tolist()\n",
    "    output_df = pd.DataFrame(output_list, columns=names)\n",
    "    return output_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collector: collected 0 objects.\n"
     ]
    }
   ],
   "source": [
    "def combine_csv(csv_list, names):\n",
    "    final_df = pd.DataFrame(columns=names)\n",
    "    for index, csv in enumerate(csv_list):\n",
    "        temp_df = pd.read_csv(csv, names=names)\n",
    "        final_df = pd.concat([final_df, temp_df])\n",
    "\n",
    "    return final_df\n",
    "\n",
    "\n",
    "def get_dataset():\n",
    "    names = [\n",
    "        \"dim1\",\n",
    "        \"dim2\",\n",
    "        \"dim3\",\n",
    "        \"dim4\",\n",
    "        \"dim5\",\n",
    "        \"dim6\",\n",
    "        \"dim7\",\n",
    "        \"dim8\",\n",
    "        \"dim9\",\n",
    "        \"dim10\",\n",
    "        \"dim11\",\n",
    "        \"dim12\",\n",
    "        \"dim13\",\n",
    "        \"dim14\",\n",
    "        \"dim15\",\n",
    "        \"dim16\",\n",
    "        \"dim17\",\n",
    "        \"dim18\",\n",
    "        \"dim19\",\n",
    "        \"dim20\",\n",
    "        \"dim21\",\n",
    "        \"dim22\",\n",
    "        \"dim23\",\n",
    "        \"dim24\",\n",
    "        \"dim25\",\n",
    "        \"dim26\",\n",
    "        \"dim27\",\n",
    "        \"dim28\",\n",
    "        \"dim29\",\n",
    "        \"dim30\",\n",
    "        \"dim31\",\n",
    "        \"dim32\",\n",
    "        \"class\",\n",
    "    ]\n",
    "\n",
    "    experiment_type = int(\n",
    "        input(\n",
    "            \"Select one of the following: \\n1. Nilsimsa Per-Packet Devices \\n2. Nilsimsa Per-Packet Categories \\n3. Nilsimsa Identical Devices \\n4. SimHash Identical Devices \\n5. 100x Noise\"\n",
    "        )\n",
    "    )\n",
    "    c_uc = int(input(\"Select one of the following: \\n1. Cleaned \\n2. Uncleaned\"))\n",
    "\n",
    "    if experiment_type == 1 and c_uc == 1:\n",
    "        noise = int(\n",
    "            input(\n",
    "                \"Select one of the following: \\n1. Random \\n2. IoT Cleaned \\n3. IoT Uncleaned \\n4. Network Cleaned \\n5. Network Uncleaned \\n6. None\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if noise != 6:\n",
    "\n",
    "            if noise == 1:\n",
    "                dataset = read_csv(path_to_per_packet_cleaned_devices, names=names)\n",
    "                dataset = noise_generator(dataset, names)\n",
    "                name = \"cleaned_devices-random\"\n",
    "            elif noise == 2:\n",
    "                csv_list = [\n",
    "                    path_to_per_packet_cleaned_devices,\n",
    "                    path_to_iot_noise_cleaned,\n",
    "                ]\n",
    "                dataset = combine_csv(csv_list, names)\n",
    "                name = \"cleaned_devices-cleaned_iot\"\n",
    "            elif noise == 3:\n",
    "                csv_list = [\n",
    "                    path_to_per_packet_cleaned_devices,\n",
    "                    path_to_iot_noise_uncleaned,\n",
    "                ]\n",
    "                dataset = combine_csv(csv_list, names)\n",
    "                name = \"cleaned_devices-uncleaned_iot\"\n",
    "            elif noise == 4:\n",
    "                csv_list = [\n",
    "                    path_to_per_packet_cleaned_devices,\n",
    "                    path_to_network_noise_cleaned,\n",
    "                ]\n",
    "                dataset = combine_csv(csv_list, names)\n",
    "                name = \"cleaned_devices-cleaned_network\"\n",
    "            elif noise == 5:\n",
    "                csv_list = [\n",
    "                    path_to_per_packet_cleaned_devices,\n",
    "                    path_to_network_noise_uncleaned,\n",
    "                ]\n",
    "                dataset = combine_csv(csv_list, names)\n",
    "                name = \"cleaned_devices-uncleaned_network\"\n",
    "        else:\n",
    "            dataset = read_csv(path_to_per_packet_cleaned_devices, names=names)\n",
    "            name = \"cleaned_devices\"\n",
    "    elif experiment_type == 1 and c_uc == 2:\n",
    "        noise = int(\n",
    "            input(\n",
    "                \"Select one of the following: \\n1. Random \\n2. IoT Cleaned \\n3. IoT Uncleaned \\n4. Network Cleaned \\n5. Network Uncleaned \\n6. None\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if noise != 6:\n",
    "\n",
    "            if noise == 1:\n",
    "                dataset = read_csv(path_to_per_packet_uncleaned_devices, names=names)\n",
    "                dataset = noise_generator(dataset, names)\n",
    "                name = \"uncleaned_devices-random\"\n",
    "            elif noise == 2:\n",
    "                csv_list = [\n",
    "                    path_to_per_packet_uncleaned_devices,\n",
    "                    path_to_iot_noise_cleaned,\n",
    "                ]\n",
    "                dataset = combine_csv(csv_list, names)\n",
    "                name = \"uncleaned_devices-cleaned_iot\"\n",
    "            elif noise == 3:\n",
    "                csv_list = [\n",
    "                    path_to_per_packet_uncleaned_devices,\n",
    "                    path_to_iot_noise_uncleaned,\n",
    "                ]\n",
    "                dataset = combine_csv(csv_list, names)\n",
    "                name = \"uncleaned_devices-uncleaned_iot\"\n",
    "            elif noise == 4:\n",
    "                csv_list = [\n",
    "                    path_to_per_packet_uncleaned_devices,\n",
    "                    path_to_network_noise_cleaned,\n",
    "                ]\n",
    "                dataset = combine_csv(csv_list, names)\n",
    "                name = \"uncleaned_devices-cleaned_network\"\n",
    "            elif noise == 5:\n",
    "                csv_list = [\n",
    "                    path_to_per_packet_uncleaned_devices,\n",
    "                    path_to_network_noise_uncleaned,\n",
    "                ]\n",
    "                dataset = combine_csv(csv_list, names)\n",
    "                name = \"uncleaned_devices-uncleaned-network\"\n",
    "        else:\n",
    "            dataset = read_csv(path_to_per_packet_uncleaned_devices, names=names)\n",
    "            name = \"uncleaned_devices\"\n",
    "    elif experiment_type == 2 and c_uc == 1:\n",
    "        noise = int(\n",
    "            input(\n",
    "                \"Select one of the following: \\n1. Random \\n2. IoT Cleaned \\n3. IoT Uncleaned \\n4. Network Cleaned \\n5. Network Uncleaned \\n6. None\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if noise != 6:\n",
    "\n",
    "            if noise == 1:\n",
    "                dataset = read_csv(path_to_per_packet_cleaned_categories, names=names)\n",
    "                dataset = noise_generator(dataset, names)\n",
    "                name = \"cleaned_categories-random\"\n",
    "            elif noise == 2:\n",
    "                csv_list = [\n",
    "                    path_to_per_packet_cleaned_categories,\n",
    "                    path_to_iot_noise_cleaned,\n",
    "                ]\n",
    "                dataset = combine_csv(csv_list, names)\n",
    "                name = \"cleaned_categories-cleaned_iot\"\n",
    "            elif noise == 3:\n",
    "                csv_list = [\n",
    "                    path_to_per_packet_cleaned_categories,\n",
    "                    path_to_iot_noise_uncleaned,\n",
    "                ]\n",
    "                dataset = combine_csv(csv_list, names)\n",
    "                name = \"cleaned_categories-uncleaned_iot\"\n",
    "            elif noise == 4:\n",
    "                csv_list = [\n",
    "                    path_to_per_packet_cleaned_categories,\n",
    "                    path_to_network_noise_cleaned,\n",
    "                ]\n",
    "                dataset = combine_csv(csv_list, names)\n",
    "                name = \"cleaned_categories-cleaned_network\"\n",
    "            elif noise == 5:\n",
    "                csv_list = [\n",
    "                    path_to_per_packet_cleaned_categories,\n",
    "                    path_to_network_noise_uncleaned,\n",
    "                ]\n",
    "                dataset = combine_csv(csv_list, names)\n",
    "                name = \"cleaned_categories-uncleaned_network\"\n",
    "        else:\n",
    "            dataset = read_csv(path_to_per_packet_cleaned_categories, names=names)\n",
    "            name = \"cleaned_categories\"\n",
    "    elif experiment_type == 2 and c_uc == 2:\n",
    "        noise = int(\n",
    "            input(\n",
    "                \"Select one of the following: \\n1. Random \\n2. IoT Cleaned \\n3. IoT Uncleaned \\n4. Network Cleaned \\n5. Network Uncleaned \\n6. None\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if noise != 6:\n",
    "\n",
    "            if noise == 1:\n",
    "                dataset = read_csv(path_to_per_packet_uncleaned_categories, names=names)\n",
    "                dataset = noise_generator(dataset, names)\n",
    "                name = \"uncleaned_categories-random\"\n",
    "            elif noise == 2:\n",
    "                csv_list = [\n",
    "                    path_to_per_packet_uncleaned_categories,\n",
    "                    path_to_iot_noise_cleaned,\n",
    "                ]\n",
    "                dataset = combine_csv(csv_list, names)\n",
    "                name = \"uncleaned_categories-cleaned_iot\"\n",
    "            elif noise == 3:\n",
    "                csv_list = [\n",
    "                    path_to_per_packet_uncleaned_categories,\n",
    "                    path_to_iot_noise_uncleaned,\n",
    "                ]\n",
    "                dataset = combine_csv(csv_list, names)\n",
    "                name = \"uncleaned_categories-uncleaned_iot\"\n",
    "            elif noise == 4:\n",
    "                csv_list = [\n",
    "                    path_to_per_packet_uncleaned_categories,\n",
    "                    path_to_network_noise_cleaned,\n",
    "                ]\n",
    "                dataset = combine_csv(csv_list, names)\n",
    "                name = \"uncleaned_categories-cleaned_network\"\n",
    "            elif noise == 5:\n",
    "                csv_list = [\n",
    "                    path_to_per_packet_uncleaned_categories,\n",
    "                    path_to_network_noise_uncleaned,\n",
    "                ]\n",
    "                dataset = combine_csv(csv_list, names)\n",
    "                name = \"uncleaned_categories-uncleaned_network\"\n",
    "        else:\n",
    "            dataset = read_csv(path_to_per_packet_uncleaned_categories, names=names)\n",
    "            name = \"uncleaned_categories\"\n",
    "    elif experiment_type == 3:\n",
    "        device = int(input(\"Select one of the following: \\n1. Plug \\n2. Bulb \\n3. Cam\"))\n",
    "        i_ni = int(\n",
    "            input(\"Select one of the following: \\n1. Interaction \\n2. No Interaction\")\n",
    "        )\n",
    "\n",
    "        if device == 1 and c_uc == 1 and i_ni == 1:\n",
    "            csv_list = os.listdir(path_to_same_plug_cleaned_interaction)\n",
    "            csv_list = [\n",
    "                f\"{path_to_same_plug_cleaned_interaction + i}\" for i in csv_list\n",
    "            ]\n",
    "            dataset = combine_csv(csv_list, names)\n",
    "            name = \"plug-cleaned-interaction\"\n",
    "        elif device == 1 and c_uc == 1 and i_ni == 2:\n",
    "            csv_list = os.listdir(path_to_same_plug_cleaned_no_interaction)\n",
    "            csv_list = [\n",
    "                f\"{path_to_same_plug_cleaned_no_interaction + i}\" for i in csv_list\n",
    "            ]\n",
    "            dataset = combine_csv(csv_list, names)\n",
    "            name = \"plug-cleaned-no_interaction\"\n",
    "        elif device == 1 and c_uc == 2 and i_ni == 1:\n",
    "            csv_list = os.listdir(path_to_same_plug_uncleaned_interaction)\n",
    "            csv_list = [\n",
    "                f\"{path_to_same_plug_uncleaned_interaction + i}\" for i in csv_list\n",
    "            ]\n",
    "            dataset = combine_csv(csv_list, names)\n",
    "            name = \"plug-uncleaned-interaction\"\n",
    "        elif device == 1 and c_uc == 2 and i_ni == 2:\n",
    "            csv_list = os.listdir(path_to_same_plug_uncleaned_no_interaction)\n",
    "            csv_list = [\n",
    "                f\"{path_to_same_plug_uncleaned_no_interaction + i}\" for i in csv_list\n",
    "            ]\n",
    "            dataset = combine_csv(csv_list, names)\n",
    "            name = \"plug-uncleaned-no_interaction\"\n",
    "        elif device == 2 and c_uc == 1 and i_ni == 1:\n",
    "            csv_list = os.listdir(path_to_same_bulb_cleaned_interaction)\n",
    "            csv_list = [\n",
    "                f\"{path_to_same_bulb_cleaned_interaction + i}\" for i in csv_list\n",
    "            ]\n",
    "            dataset = combine_csv(csv_list, names)\n",
    "            name = \"bulb-cleaned-interaction\"\n",
    "        elif device == 2 and c_uc == 1 and i_ni == 2:\n",
    "            csv_list = os.listdir(path_to_same_bulb_cleaned_no_interaction)\n",
    "            csv_list = [\n",
    "                f\"{path_to_same_bulb_cleaned_no_interaction + i}\" for i in csv_list\n",
    "            ]\n",
    "            dataset = combine_csv(csv_list, names)\n",
    "            name = \"bulb-cleaned-no_interaction\"\n",
    "        elif device == 2 and c_uc == 2 and i_ni == 1:\n",
    "            csv_list = os.listdir(path_to_same_bulb_uncleaned_interaction)\n",
    "            csv_list = [\n",
    "                f\"{path_to_same_bulb_uncleaned_interaction + i}\" for i in csv_list\n",
    "            ]\n",
    "            dataset = combine_csv(csv_list, names)\n",
    "            name = \"bulb-uncleaned-interaction\"\n",
    "        elif device == 2 and c_uc == 2 and i_ni == 2:\n",
    "            csv_list = os.listdir(path_to_same_bulb_uncleaned_no_interaction)\n",
    "            csv_list = [\n",
    "                f\"{path_to_same_bulb_uncleaned_no_interaction + i}\" for i in csv_list\n",
    "            ]\n",
    "            dataset = combine_csv(csv_list, names)\n",
    "            name = \"bulb-uncleaned-no_interaction\"\n",
    "        elif device == 3 and c_uc == 1 and i_ni == 1:\n",
    "            csv_list = os.listdir(path_to_same_cam_cleaned_interaction)\n",
    "            csv_list = [f\"{path_to_same_cam_cleaned_interaction + i}\" for i in csv_list]\n",
    "            dataset = combine_csv(csv_list, names)\n",
    "            name = \"cam-cleaned-interaction\"\n",
    "        elif device == 3 and c_uc == 1 and i_ni == 2:\n",
    "            csv_list = os.listdir(path_to_same_cam_cleaned_no_interaction)\n",
    "            csv_list = [\n",
    "                f\"{path_to_same_cam_cleaned_no_interaction + i}\" for i in csv_list\n",
    "            ]\n",
    "            dataset = combine_csv(csv_list, names)\n",
    "            name = \"cam-cleaned-no_interaction\"\n",
    "        elif device == 3 and c_uc == 2 and i_ni == 1:\n",
    "            csv_list = os.listdir(path_to_same_cam_uncleaned_interaction)\n",
    "            csv_list = [\n",
    "                f\"{path_to_same_cam_uncleaned_interaction + i}\" for i in csv_list\n",
    "            ]\n",
    "            dataset = combine_csv(csv_list, names)\n",
    "            name = \"cam-uncleaned-interaction\"\n",
    "        elif device == 3 and c_uc == 2 and i_ni == 2:\n",
    "            csv_list = os.listdir(path_to_same_cam_uncleaned_no_interaction)\n",
    "            csv_list = [\n",
    "                f\"{path_to_same_cam_uncleaned_no_interaction + i}\" for i in csv_list\n",
    "            ]\n",
    "            dataset = combine_csv(csv_list, names)\n",
    "            name = \"cam-uncleaned-no_interaction\"\n",
    "\n",
    "    elif experiment_type == 4:\n",
    "\n",
    "        accum = int(\n",
    "            input(\n",
    "                \"Select one of the following accumulator sizes: \\n128 \\n256 \\n512 \\n1024\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if accum == 128:\n",
    "            names = [\n",
    "                \"dim1\",\n",
    "                \"dim2\",\n",
    "                \"dim3\",\n",
    "                \"dim4\",\n",
    "                \"dim5\",\n",
    "                \"dim6\",\n",
    "                \"dim7\",\n",
    "                \"dim8\",\n",
    "                \"dim9\",\n",
    "                \"dim10\",\n",
    "                \"dim11\",\n",
    "                \"dim12\",\n",
    "                \"dim13\",\n",
    "                \"dim14\",\n",
    "                \"dim15\",\n",
    "                \"dim16\",\n",
    "                \"class\",\n",
    "            ]\n",
    "        elif accum == 256:\n",
    "            names = [\n",
    "                \"dim1\",\n",
    "                \"dim2\",\n",
    "                \"dim3\",\n",
    "                \"dim4\",\n",
    "                \"dim5\",\n",
    "                \"dim6\",\n",
    "                \"dim7\",\n",
    "                \"dim8\",\n",
    "                \"dim9\",\n",
    "                \"dim10\",\n",
    "                \"dim11\",\n",
    "                \"dim12\",\n",
    "                \"dim13\",\n",
    "                \"dim14\",\n",
    "                \"dim15\",\n",
    "                \"dim16\",\n",
    "                \"dim17\",\n",
    "                \"dim18\",\n",
    "                \"dim19\",\n",
    "                \"dim20\",\n",
    "                \"dim21\",\n",
    "                \"dim22\",\n",
    "                \"dim23\",\n",
    "                \"dim24\",\n",
    "                \"dim25\",\n",
    "                \"dim26\",\n",
    "                \"dim27\",\n",
    "                \"dim28\",\n",
    "                \"dim29\",\n",
    "                \"dim30\",\n",
    "                \"dim31\",\n",
    "                \"dim32\",\n",
    "                \"class\",\n",
    "            ]\n",
    "        elif accum == 512:\n",
    "            names = [\n",
    "                \"dim1\",\n",
    "                \"dim2\",\n",
    "                \"dim3\",\n",
    "                \"dim4\",\n",
    "                \"dim5\",\n",
    "                \"dim6\",\n",
    "                \"dim7\",\n",
    "                \"dim8\",\n",
    "                \"dim9\",\n",
    "                \"dim10\",\n",
    "                \"dim11\",\n",
    "                \"dim12\",\n",
    "                \"dim13\",\n",
    "                \"dim14\",\n",
    "                \"dim15\",\n",
    "                \"dim16\",\n",
    "                \"dim17\",\n",
    "                \"dim18\",\n",
    "                \"dim19\",\n",
    "                \"dim20\",\n",
    "                \"dim21\",\n",
    "                \"dim22\",\n",
    "                \"dim23\",\n",
    "                \"dim24\",\n",
    "                \"dim25\",\n",
    "                \"dim26\",\n",
    "                \"dim27\",\n",
    "                \"dim28\",\n",
    "                \"dim29\",\n",
    "                \"dim30\",\n",
    "                \"dim31\",\n",
    "                \"dim32\",\n",
    "                \"dim33\",\n",
    "                \"dim34\",\n",
    "                \"dim35\",\n",
    "                \"dim36\",\n",
    "                \"dim37\",\n",
    "                \"dim38\",\n",
    "                \"dim39\",\n",
    "                \"dim40\",\n",
    "                \"dim41\",\n",
    "                \"dim42\",\n",
    "                \"dim43\",\n",
    "                \"dim44\",\n",
    "                \"dim45\",\n",
    "                \"dim46\",\n",
    "                \"dim47\",\n",
    "                \"dim48\",\n",
    "                \"dim49\",\n",
    "                \"dim50\",\n",
    "                \"dim51\",\n",
    "                \"dim52\",\n",
    "                \"dim53\",\n",
    "                \"dim54\",\n",
    "                \"dim55\",\n",
    "                \"dim56\",\n",
    "                \"dim57\",\n",
    "                \"dim58\",\n",
    "                \"dim59\",\n",
    "                \"dim60\",\n",
    "                \"dim61\",\n",
    "                \"dim62\",\n",
    "                \"dim63\",\n",
    "                \"dim64\",\n",
    "                \"class\",\n",
    "            ]\n",
    "        if accum == 1024:\n",
    "            names = [\n",
    "                \"dim1\",\n",
    "                \"dim2\",\n",
    "                \"dim3\",\n",
    "                \"dim4\",\n",
    "                \"dim5\",\n",
    "                \"dim6\",\n",
    "                \"dim7\",\n",
    "                \"dim8\",\n",
    "                \"dim9\",\n",
    "                \"dim10\",\n",
    "                \"dim11\",\n",
    "                \"dim12\",\n",
    "                \"dim13\",\n",
    "                \"dim14\",\n",
    "                \"dim15\",\n",
    "                \"dim16\",\n",
    "                \"dim17\",\n",
    "                \"dim18\",\n",
    "                \"dim19\",\n",
    "                \"dim20\",\n",
    "                \"dim21\",\n",
    "                \"dim22\",\n",
    "                \"dim23\",\n",
    "                \"dim24\",\n",
    "                \"dim25\",\n",
    "                \"dim26\",\n",
    "                \"dim27\",\n",
    "                \"dim28\",\n",
    "                \"dim29\",\n",
    "                \"dim30\",\n",
    "                \"dim31\",\n",
    "                \"dim32\",\n",
    "                \"dim33\",\n",
    "                \"dim34\",\n",
    "                \"dim35\",\n",
    "                \"dim36\",\n",
    "                \"dim37\",\n",
    "                \"dim38\",\n",
    "                \"dim39\",\n",
    "                \"dim40\",\n",
    "                \"dim41\",\n",
    "                \"dim42\",\n",
    "                \"dim43\",\n",
    "                \"dim44\",\n",
    "                \"dim45\",\n",
    "                \"dim46\",\n",
    "                \"dim47\",\n",
    "                \"dim48\",\n",
    "                \"dim49\",\n",
    "                \"dim50\",\n",
    "                \"dim51\",\n",
    "                \"dim52\",\n",
    "                \"dim53\",\n",
    "                \"dim54\",\n",
    "                \"dim55\",\n",
    "                \"dim56\",\n",
    "                \"dim57\",\n",
    "                \"dim58\",\n",
    "                \"dim59\",\n",
    "                \"dim60\",\n",
    "                \"dim61\",\n",
    "                \"dim62\",\n",
    "                \"dim63\",\n",
    "                \"dim64\",\n",
    "                \"dim65\",\n",
    "                \"dim66\",\n",
    "                \"dim67\",\n",
    "                \"dim68\",\n",
    "                \"dim69\",\n",
    "                \"dim70\",\n",
    "                \"dim71\",\n",
    "                \"dim72\",\n",
    "                \"dim73\",\n",
    "                \"dim74\",\n",
    "                \"dim75\",\n",
    "                \"dim76\",\n",
    "                \"dim77\",\n",
    "                \"dim78\",\n",
    "                \"dim79\",\n",
    "                \"dim80\",\n",
    "                \"dim81\",\n",
    "                \"dim82\",\n",
    "                \"dim83\",\n",
    "                \"dim84\",\n",
    "                \"dim85\",\n",
    "                \"dim86\",\n",
    "                \"dim87\",\n",
    "                \"dim88\",\n",
    "                \"dim89\",\n",
    "                \"dim90\",\n",
    "                \"dim91\",\n",
    "                \"dim92\",\n",
    "                \"dim93\",\n",
    "                \"dim94\",\n",
    "                \"dim95\",\n",
    "                \"dim96\",\n",
    "                \"dim97\",\n",
    "                \"dim98\",\n",
    "                \"dim99\",\n",
    "                \"dim100\",\n",
    "                \"dim101\",\n",
    "                \"dim102\",\n",
    "                \"dim103\",\n",
    "                \"dim104\",\n",
    "                \"dim105\",\n",
    "                \"dim106\",\n",
    "                \"dim107\",\n",
    "                \"dim108\",\n",
    "                \"dim109\",\n",
    "                \"dim110\",\n",
    "                \"dim111\",\n",
    "                \"dim112\",\n",
    "                \"dim113\",\n",
    "                \"dim114\",\n",
    "                \"dim115\",\n",
    "                \"dim116\",\n",
    "                \"dim117\",\n",
    "                \"dim118\",\n",
    "                \"dim119\",\n",
    "                \"dim120\",\n",
    "                \"dim121\",\n",
    "                \"dim122\",\n",
    "                \"dim123\",\n",
    "                \"dim124\",\n",
    "                \"dim125\",\n",
    "                \"dim126\",\n",
    "                \"dim127\",\n",
    "                \"dim128\",\n",
    "                \"class\",\n",
    "            ]\n",
    "\n",
    "        window = int(input(\"Select one of the following window sizes: \\n4 \\n5 \\n6\"))\n",
    "        if window == 4:\n",
    "            combo = int(\n",
    "                input(\"Select one of the following combination sizes: \\n2 \\n3 \\n4\")\n",
    "            )\n",
    "        elif window == 5:\n",
    "            combo = int(\n",
    "                input(\"Select one of the following combination sizes: \\n2 \\n3 \\n4 \\n5\")\n",
    "            )\n",
    "        elif window == 6:\n",
    "            combo = int(\n",
    "                input(\n",
    "                    \"Select one of the following combination sizes: \\n2 \\n3 \\n4 \\n5 \\n6\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if c_uc == 1:\n",
    "            target_dir = f\"{path_to_simhash}{accum}/win_{window}/comb_{combo}/cleaned/\"\n",
    "            csv_list = os.listdir(target_dir)\n",
    "            csv_list = [f\"{target_dir + i}\" for i in csv_list]\n",
    "            name = f\"SimHash-{accum}-win_{window}-combo_{combo}-cleaned\"\n",
    "        elif c_uc == 2:\n",
    "            target_dir = (\n",
    "                f\"{path_to_simhash}{accum}/win_{window}/comb_{combo}/uncleaned/\"\n",
    "            )\n",
    "            csv_list = os.listdir(target_dir)\n",
    "            csv_list = [f\"{target_dir + i}\" for i in csv_list]\n",
    "            name = f\"SimHash-{accum}-win_{window}-combo_{combo}-uncleaned\"\n",
    "\n",
    "        dataset = combine_csv(csv_list, names)\n",
    "\n",
    "    elif experiment_type == 5:\n",
    "        hash_alg = int(\n",
    "            input(\n",
    "                \"Select on of the following hashing algorithms: \\n1. Nilsimsa \\n2.FlexHash\"\n",
    "            )\n",
    "        )\n",
    "        noise = int(\n",
    "            input(\n",
    "                \"Select one of the following: \\n1. Random \\n2. IoT Cleaned \\n3. IoT Uncleaned \\n4. Network Cleaned \\n5. Network Uncleaned\"\n",
    "            )\n",
    "        )\n",
    "        if hash_alg == 1:\n",
    "            device = int(\n",
    "                input(\"Select one of the following: \\n1. Plug \\n2. Bulb \\n3. Cam\")\n",
    "            )\n",
    "            i_ni = int(\n",
    "                input(\n",
    "                    \"Select one of the following: \\n1. Interaction \\n2. No Interaction\"\n",
    "                )\n",
    "            )\n",
    "            device_num = int(input(\"Select a device number (1-8): \"))\n",
    "\n",
    "            if device == 1 and c_uc == 1 and i_ni == 1:\n",
    "                csv_list = sorted(os.listdir(path_to_same_plug_cleaned_interaction))\n",
    "                csv_list = [\n",
    "                    path_to_same_plug_cleaned_interaction + csv_list[device_num - 1]\n",
    "                ]\n",
    "\n",
    "                name = f\"plug-{device_num}-cleaned-interaction_100x\"\n",
    "            elif device == 1 and c_uc == 1 and i_ni == 2:\n",
    "                csv_list = sorted(os.listdir(path_to_same_plug_cleaned_no_interaction))\n",
    "                csv_list = [\n",
    "                    path_to_same_plug_cleaned_no_interaction + csv_list[device_num - 1]\n",
    "                ]\n",
    "\n",
    "                name = f\"plug-{device_num}-cleaned-no_interaction_100x\"\n",
    "            elif device == 1 and c_uc == 2 and i_ni == 1:\n",
    "                csv_list = sorted(os.listdir(path_to_same_plug_uncleaned_interaction))\n",
    "                csv_list = [\n",
    "                    path_to_same_plug_uncleaned_interaction + csv_list[device_num - 1]\n",
    "                ]\n",
    "\n",
    "                name = f\"plug-{device_num}-uncleaned-interaction_100x\"\n",
    "            elif device == 1 and c_uc == 2 and i_ni == 2:\n",
    "                csv_list = sorted(\n",
    "                    os.listdir(path_to_same_plug_uncleaned_no_interaction)\n",
    "                )\n",
    "                csv_list = [\n",
    "                    path_to_same_plug_uncleaned_no_interaction\n",
    "                    + csv_list[device_num - 1]\n",
    "                ]\n",
    "\n",
    "                name = f\"plug-{device_num}-uncleaned-no_interaction_100x\"\n",
    "            elif device == 2 and c_uc == 1 and i_ni == 1:\n",
    "                csv_list = sorted(os.listdir(path_to_same_bulb_cleaned_interaction))\n",
    "                csv_list = [\n",
    "                    path_to_same_bulb_cleaned_interaction + csv_list[device_num - 1]\n",
    "                ]\n",
    "\n",
    "                name = f\"bulb-{device_num}-cleaned-interaction_100x\"\n",
    "            elif device == 2 and c_uc == 1 and i_ni == 2:\n",
    "                csv_list = sorted(os.listdir(path_to_same_bulb_cleaned_no_interaction))\n",
    "                csv_list = [\n",
    "                    path_to_same_bulb_cleaned_no_interaction + csv_list[device_num - 1]\n",
    "                ]\n",
    "\n",
    "                name = f\"bulb-{device_num}-cleaned-no_interaction_100x\"\n",
    "            elif device == 2 and c_uc == 2 and i_ni == 1:\n",
    "                csv_list = sorted(os.listdir(path_to_same_bulb_uncleaned_interaction))\n",
    "                csv_list = [\n",
    "                    path_to_same_bulb_uncleaned_interaction + csv_list[device_num - 1]\n",
    "                ]\n",
    "\n",
    "                name = f\"bulb-{device_num}-uncleaned-interaction_100x\"\n",
    "            elif device == 2 and c_uc == 2 and i_ni == 2:\n",
    "                csv_list = sorted(\n",
    "                    os.listdir(path_to_same_bulb_uncleaned_no_interaction)\n",
    "                )\n",
    "                csv_list = [\n",
    "                    path_to_same_bulb_uncleaned_no_interaction\n",
    "                    + csv_list[device_num - 1]\n",
    "                ]\n",
    "\n",
    "                name = f\"bulb-{device_num}-uncleaned-no_interaction_100x\"\n",
    "            elif device == 3 and c_uc == 1 and i_ni == 1:\n",
    "                csv_list = sorted(os.listdir(path_to_same_cam_cleaned_interaction))\n",
    "                csv_list = [\n",
    "                    path_to_same_cam_cleaned_interaction + csv_list[device_num - 1]\n",
    "                ]\n",
    "\n",
    "                name = f\"cam-{device_num}-cleaned-interaction_100x\"\n",
    "            elif device == 3 and c_uc == 1 and i_ni == 2:\n",
    "                csv_list = sorted(os.listdir(path_to_same_cam_cleaned_no_interaction))\n",
    "                csv_list = [\n",
    "                    path_to_same_cam_cleaned_no_interaction + csv_list[device_num - 1]\n",
    "                ]\n",
    "\n",
    "                name = f\"cam-{device_num}-cleaned-no_interaction_100x\"\n",
    "            elif device == 3 and c_uc == 2 and i_ni == 1:\n",
    "                csv_list = sorted(os.listdir(path_to_same_cam_uncleaned_interaction))\n",
    "                csv_list = [\n",
    "                    path_to_same_cam_uncleaned_interaction + csv_list[device_num - 1]\n",
    "                ]\n",
    "\n",
    "                name = f\"cam-{device_num}-uncleaned-interaction_100x\"\n",
    "            elif device == 3 and c_uc == 2 and i_ni == 2:\n",
    "                csv_list = sorted(os.listdir(path_to_same_cam_uncleaned_no_interaction))\n",
    "                csv_list = [\n",
    "                    path_to_same_cam_uncleaned_no_interaction + csv_list[device_num - 1]\n",
    "                ]\n",
    "\n",
    "                name = f\"cam-{device_num}-uncleaned-no_interaction_100x\"\n",
    "\n",
    "            if noise == 2:\n",
    "                csv_list.append(path_to_iot_noise_cleaned)\n",
    "                name += \"-cleaned_iot\"\n",
    "            elif noise == 3:\n",
    "                csv_list.append(path_to_iot_noise_uncleaned)\n",
    "                name += \"-uncleaned_iot\"\n",
    "            elif noise == 4:\n",
    "                csv_list.append(path_to_network_noise_cleaned)\n",
    "                name += \"-cleaned_network\"\n",
    "            elif noise == 5:\n",
    "                csv_list.append(path_to_network_noise_uncleaned)\n",
    "                name += \"-uncleaned_network\"\n",
    "\n",
    "            dataset = combine_csv(csv_list, names)\n",
    "\n",
    "            if noise == 1:\n",
    "                dataset = noise_generator(dataset, names, False)\n",
    "                name += \"-random\"\n",
    "\n",
    "            print(csv_list, name)\n",
    "\n",
    "    return dataset, name\n",
    "\n",
    "\n",
    "dataset, name_of_current_data = get_dataset()\n",
    "collected = gc.collect()\n",
    "print(\"Garbage collector: collected %d objects.\" % (collected))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Total samples in cam-cleaned-no_interaction: 322434 ***\n",
      "*** Samples for device: cam-1 in cam-cleaned-no_interaction: 40774 (0.12645688730096702%) ***\n",
      "*** Samples for device: cam-2 in cam-cleaned-no_interaction: 40506 (0.12562570944751483%) ***\n",
      "*** Samples for device: cam-3 in cam-cleaned-no_interaction: 40396 (0.12528455435841132%) ***\n",
      "*** Samples for device: cam-4 in cam-cleaned-no_interaction: 39520 (0.12256771928518705%) ***\n",
      "*** Samples for device: cam-5 in cam-cleaned-no_interaction: 40618 (0.12597306735642022%) ***\n",
      "*** Samples for device: cam-6 in cam-cleaned-no_interaction: 40446 (0.1254396248534584%) ***\n",
      "*** Samples for device: cam-7 in cam-cleaned-no_interaction: 40299 (0.12498371759802006%) ***\n",
      "*** Samples for device: cam-8 in cam-cleaned-no_interaction: 39875 (0.12366871980002109%) ***\n",
      "Garbage collector: collected 0 objects.\n",
      "*** Dataset Loaded ***\n"
     ]
    }
   ],
   "source": [
    "print(f\"*** Total samples in {name_of_current_data}: {len(dataset.index)} ***\")\n",
    "for device_name in sorted(dataset[\"class\"].unique()):\n",
    "    num_samples = len((dataset[dataset[\"class\"] == device_name]).index)\n",
    "    print(\n",
    "        f\"*** Samples for device: {device_name} in {name_of_current_data}: {num_samples} ({num_samples/dataset.shape[0]}%) ***\"\n",
    "    )\n",
    "\n",
    "# classes_to_remove = [\"light-4\", \"light-5\", \"light-6\", \"light-7\", \"light-8\",]\n",
    "# for item in classes_to_remove:\n",
    "#     dataset = remove_class(item, dataset)\n",
    "#     dataset.dropna(inplace=True)\n",
    "\n",
    "# Uncomment this line to take only a portion of the data\n",
    "# dataset = dataset.head(len(dataset.index)//10)\n",
    "\n",
    "# x is the entire dataframe except for the class column\n",
    "x = dataset.drop([\"class\"], axis=1)\n",
    "\n",
    "# y_original is an unaltered list of all values in the class column\n",
    "y_original = dataset[\"class\"].values.tolist()\n",
    "\n",
    "# y is a dataframe of only the class column and the values have been converted to numeric representation\n",
    "y = dataset[\"class\"]\n",
    "counter = 0\n",
    "y_temp = dataset[\"class\"].tolist()\n",
    "for unique_value in sorted(y.unique()):\n",
    "    for index, value in enumerate(y):\n",
    "        if value == unique_value:\n",
    "            y_temp[index] = counter\n",
    "    counter += 1\n",
    "dataset[\"class\"] = y_temp\n",
    "y = dataset[\"class\"]\n",
    "labels_numeric = dataset[\"class\"].unique()\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x.values, y.values, test_size=.2, stratify=y.values)\n",
    "\n",
    "del dataset\n",
    "# del x\n",
    "# del y\n",
    "del y_original\n",
    "del y_temp\n",
    "del labels_numeric\n",
    "collected = gc.collect()\n",
    "print(\"Garbage collector: collected %d objects.\" % (collected))\n",
    "\n",
    "print(\"*** Dataset Loaded ***\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# param_grid_HGBC = {\"learning_rate\": [0.01, 0.001, .1], \"max_leaf_nodes\": [None, 31, 50, 100], \"max_depth\": [None, 8, 16, 32, 64, 128], \"min_samples_leaf\": [5, 20, 100], \"l2_regularization\": [0, .1, .5, 1]}\n",
    "# HGBC = ensemble.HistGradientBoostingClassifier()\n",
    "# clf_HGBC = GridSearchCV(HGBC, param_grid_HGBC, n_jobs=20).fit(x.values, y.values)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# param_grid_RFC = {\"n_estimators\": [50, 100, 200, 500, 1000], \"min_samples_leaf\": [1, 5, 10, 20, 50, 100], \"min_samples_split\": [1, 2, 5, 10, 20, 50, 100], \"l2_regularization\": [.1, .3, .5, .7, 1], \"max_depth\": [5, 10, 30, 50, 100, 200]}\n",
    "# RFC = ensemble.RandomForestClassifier()\n",
    "# clf_RFC = GridSearchCV(RFC, param_grid_RFC, n_jobs=20).fit(x.values, y.values)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Begin Training and Evaluating 1 ***\n",
      "*** Finished Training and Evaluating 1 ***\n",
      "Dataset Name: cam-cleaned-no_interaction\n",
      "Runtime: 4.64546799659729\n",
      "Accuracy: 0.12176445412084333\n",
      "Balanced Accuracy: 0.12128887669066196\n",
      "Weighted F1: 0.11282157223050782\n"
     ]
    }
   ],
   "source": [
    "# Spot Check Algorithms\n",
    "# x = [1000 for i in range(100)]\n",
    "# x = (* x,)\n",
    "\n",
    "models = []\n",
    "# models.append((1, ensemble.BaggingClassifier(base_estimator=ensemble.RandomForestClassifier(max_depth=10), n_estimators=50, bootstrap_features=True, n_jobs=16)))\n",
    "# models.append((1, ensemble.AdaBoostClassifier(base_estimator=ensemble.RandomForestClassifier(), n_estimators=50)))\n",
    "# models.append((2, ensemble.AdaBoostClassifier(base_estimator=ensemble.RandomForestClassifier(max_depth=10), n_estimators=50)))\n",
    "# models.append((2, MLPClassifier()))\n",
    "models.append((1, ensemble.HistGradientBoostingClassifier()))\n",
    "# models.append((2, ensemble.HistGradientBoostingClassifier(max_depth=32)))\n",
    "# models.append((3, ensemble.HistGradientBoostingClassifier(max_depth=128)))\n",
    "# models.append((2, ensemble.RandomForestClassifier()))\n",
    "# models.append((3, ensemble.AdaBoostClassifier(base_estimator=ensemble.HistGradientBoostingClassifier(), n_estimators=50)))\n",
    "# models.append((4, ensemble.AdaBoostClassifier(base_estimator=ensemble.HistGradientBoostingClassifier(max_depth=8), n_estimators=50)))\n",
    "# models.append((5, ensemble.AdaBoostClassifier(base_estimator=ensemble.HistGradientBoostingClassifier(max_depth=16), n_estimators=50)))\n",
    "# models.append((6, ensemble.AdaBoostClassifier(base_estimator=ensemble.HistGradientBoostingClassifier(max_depth=24), n_estimators=50)))\n",
    "# models.append((7, ensemble.AdaBoostClassifier(base_estimator=ensemble.HistGradientBoostingClassifier(max_depth=32), n_estimators=50)))\n",
    "# models.append((8, ensemble.AdaBoostClassifier(base_estimator=ensemble.HistGradientBoostingClassifier(), n_estimators=100)))\n",
    "# models.append((9, ensemble.AdaBoostClassifier(base_estimator=ensemble.HistGradientBoostingClassifier(max_depth=8), n_estimators=100)))\n",
    "# models.append((10, ensemble.AdaBoostClassifier(base_estimator=ensemble.HistGradientBoostingClassifier(max_depth=16), n_estimators=100)))\n",
    "# models.append((11, ensemble.AdaBoostClassifier(base_estimator=ensemble.HistGradientBoostingClassifier(max_depth=24), n_estimators=100)))\n",
    "# models.append((12, ensemble.AdaBoostClassifier(base_estimator=ensemble.HistGradientBoostingClassifier(max_depth=32), n_estimators=100)))\n",
    "# models.append((4, ensemble.AdaBoostClassifier(base_estimator=ensemble.HistGradientBoostingClassifier(max_depth=128), n_estimators=50)))\n",
    "# models.append((4, ensemble.AdaBoostClassifier(base_estimator=ensemble.HistGradientBoostingClassifier(max_depth=8), n_estimators=50)))\n",
    "# models.append((5, ensemble.AdaBoostClassifier(base_estimator=ensemble.HistGradientBoostingClassifier(max_depth=32), n_estimators=50)))\n",
    "# models.append((4, ensemble.AdaBoostClassifier(base_estimator=ensemble.HistGradientBoostingClassifier(max_depth=1), n_estimators=32)))\n",
    "# models.append((4, ensemble.AdaBoostClassifier(base_estimator=ensemble.HistGradientBoostingClassifier(max_depth=1), n_estimators=500)))\n",
    "# models.append((5, ensemble.AdaBoostClassifier(base_estimator=ensemble.HistGradientBoostingClassifier(max_depth=1), n_estimators=1000)))\n",
    "# models.append((6, ensemble.AdaBoostClassifier(base_estimator=ensemble.HistGradientBoostingClassifier(max_depth=1), n_estimators=10000)))\n",
    "# models.append((4, ensemble.AdaBoostClassifier(base_estimator=ensemble.HistGradientBoostingClassifier(l2_regularization=0.2, learning_rate=0.2, min_samples_leaf=100), n_estimators=50)))\n",
    "# models.append((1, ensemble.GradientBoostingClassifier(max_depth=10)))\n",
    "# models.append((1, ensemble.GradientBoostingClassifier(max_depth=100)))\n",
    "\n",
    "# evaluate each model\n",
    "for model_name, model in models:\n",
    "    print(f\"*** Begin Training and Evaluating {model_name} ***\")\n",
    "    start_time = time.time()\n",
    "    # print(y_train.shape)\n",
    "    # model.fit(x_train, y_train)\n",
    "    # print(f\"*** {model_name} Trained ***\")\n",
    "\n",
    "    # y_pred = model.predict(x_test)\n",
    "    # y_probas = model.predict_proba(x_test)\n",
    "\n",
    "    # weighted_acc_dict = {}\n",
    "    # for index, label in enumerate(y_test):\n",
    "    #     weighted_acc_dict[f\"{label}_count\"] += 1\n",
    "    #     if y_pred[index] == label:\n",
    "    #         weighted_acc_dict[label] += 1\n",
    "\n",
    "    # total_accuracy = accuracy_score(y_test, y_pred)\n",
    "    # total_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # print(f\"Accuracy: {total_accuracy}\")\n",
    "    # print(f\"F1: {total_f1}\")\n",
    "\n",
    "    # ******************** #\n",
    "    # Cross Validation\n",
    "    # ******************** #\n",
    "    cross_val_results = cross_validate(\n",
    "        model,\n",
    "        x.values,\n",
    "        y.values,\n",
    "        cv=7,\n",
    "        scoring=[\"accuracy\", \"balanced_accuracy\", \"f1_weighted\"],\n",
    "        n_jobs=7,\n",
    "    )\n",
    "    print(f\"*** Finished Training and Evaluating {model_name} ***\")\n",
    "    print(f\"Dataset Name: {name_of_current_data}\")\n",
    "    print(f\"Runtime: {time.time() - start_time}\")\n",
    "    print(f\"Accuracy: {mean(cross_val_results['test_accuracy'])}\")\n",
    "    print(f\"Balanced Accuracy: {mean(cross_val_results['test_balanced_accuracy'])}\")\n",
    "    # print(f\"F1: {mean(cross_val_results['test_f1'])}\")\n",
    "    print(f\"Weighted F1: {mean(cross_val_results['test_f1_weighted'])}\")\n",
    "\n",
    "    # wandb.log({f\"Total accuracy TSR on {name_of_current_data}\": total_accuracy,\n",
    "    #            \"Dataset\": name_of_current_data,\n",
    "    #            \"Num Samples\": dataset.shape[0]})\n",
    "    # wandb.log({f\"Total precision TSR on {name_of_current_data}\": total_precision,\n",
    "    #            \"Dataset\": name_of_current_data,\n",
    "    #            \"Num Samples\": dataset.shape[0]})\n",
    "    # wandb.log({f\"Total recall TSR on {name_of_current_data}\": total_recall,\n",
    "    #            \"Dataset\": name_of_current_data,\n",
    "    #            \"Num Samples\": dataset.shape[0]})\n",
    "    # wandb.log({f\"Total f1 TSR on {name_of_current_data}\": total_f1,\n",
    "    #            \"Dataset\": name_of_current_data,\n",
    "    #            \"Num Samples\": dataset.shape[0]})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# def draw_umap(data, n_neighbors, min_dist, n_components, metric, title, save_path):\n",
    "#     umap_reducer = umap.UMAP(\n",
    "#         n_neighbors=n_neighbors,\n",
    "#         min_dist=min_dist,\n",
    "#         n_components=n_components,\n",
    "#         metric=metric\n",
    "#     )\n",
    "#\n",
    "#     umap_embedding = umap_reducer.fit_transform(data)\n",
    "#\n",
    "#     fig = plt.figure(figsize=(5, 5))\n",
    "#     if n_components == 1:\n",
    "#         umap_df = pd.DataFrame(umap_embedding, columns=[\"dim1\"])\n",
    "#         umap_df[\"class\"] = y_train\n",
    "#\n",
    "#         ax = fig.add_subplot(111)\n",
    "#         ax.scatter(umap_df[\"dim1\"].values, range(len(umap_df.index)), c=umap_df[\"class\"].values, s=1)\n",
    "#     elif n_components == 2:\n",
    "#         umap_df = pd.DataFrame(umap_embedding, columns=[\"dim1\", \"dim2\"])\n",
    "#         umap_df[\"class\"] = y_train\n",
    "#\n",
    "#         ax = fig.add_subplot(111)\n",
    "#         ax.scatter(umap_df[\"dim1\"].values, umap_df[\"dim2\"].values, c=umap_df[\"class\"].values, s=1)\n",
    "#     else:\n",
    "#         umap_df = pd.DataFrame(umap_embedding, columns=[\"dim1\", \"dim2\", \"dim3\"])\n",
    "#         umap_df[\"class\"] = y_train\n",
    "#         ax = fig.add_subplot(111, projection='3d')\n",
    "#         ax.scatter(umap_df[\"dim1\"].values, umap_df[\"dim2\"].values,umap_df[\"dim3\"].values, c=umap_df[\"class\"].values, s=1)\n",
    "#\n",
    "#     plt.title(title, fontsize=8)\n",
    "#\n",
    "#     plt.savefig(save_path, dpi=1200)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# # n_neighbors adjusts the UMAP's attention to local structure vs. global relationships\n",
    "# # min_dist adjusts how close umap is allowed to place points together\n",
    "# if not os.path.isdir(f\"../figures/{name_of_current_data}/\"):\n",
    "#     os.mkdir(f\"../figures/{name_of_current_data}/\")\n",
    "#\n",
    "# num_generations = 2\n",
    "# for i in tqdm(range(3)):\n",
    "#     for j in range(num_generations):\n",
    "#         n_neighbors = 15\n",
    "#         min_dist = 0.1\n",
    "#         n_components = i+1\n",
    "#         metric = \"euclidean\"\n",
    "#         # metric = \"minkowski\"\n",
    "#\n",
    "#         title = f\"{name_of_current_data}_{n_neighbors}_{min_dist}_{n_components}_{metric}\"\n",
    "#         save_path = f\"../figures/{name_of_current_data}/{n_components}d_{j+1}.png\"\n",
    "#         # save_path = f\"/home/nthom/Documents/nilsimsa_vis/{n_components}d_{j+1}.png\"\n",
    "#         draw_umap(x_train, n_neighbors, min_dist, n_components, metric, title, save_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
