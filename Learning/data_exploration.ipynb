{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from learn import combine_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inter_intra_class_var(df):\n",
    "    # # Step 1: Separate data into different classes\n",
    "    # class_data = {}\n",
    "    # for label, group in df.groupby('Label'):\n",
    "    #     print(label)\n",
    "    #     class_data[label] = group.drop('Label', axis=1)\n",
    "\n",
    "    # # Step 2: Calculate mean for each class\n",
    "    # class_means = {}\n",
    "    # for label, class_df in class_data.items():\n",
    "    #     class_means[label] = class_df.mean()\n",
    "\n",
    "    # # Step 3: Compute intra-class variance\n",
    "    # intra_class_variance = 0\n",
    "    # for label, class_df in class_data.items():\n",
    "    #     deviation_squared = (class_df - class_means[label]) ** 2\n",
    "    #     intra_class_variance += deviation_squared.sum()\n",
    "\n",
    "    # # Step 4: Compute inter-class variance\n",
    "    # overall_mean = df.drop('Label', axis=1).mean()\n",
    "    # inter_class_variance = 0\n",
    "    # for label, class_df in class_data.items():\n",
    "    #     mean_difference = class_means[label] - overall_mean\n",
    "    #     inter_class_variance += len(class_df) * (mean_difference ** 2).sum()\n",
    "\n",
    "    # # Print results\n",
    "    # print(\"Intra-class variance:\\n\", intra_class_variance)\n",
    "    # print(\"Inter-class variance:\\n\", inter_class_variance)\n",
    "\n",
    "    # Group by label and calculate mean and variance for each class\n",
    "    grouped = df.groupby(\"Label\")\n",
    "    class_means = grouped.mean()\n",
    "    class_variances = grouped.var()\n",
    "\n",
    "    # Calculate overall mean and variance\n",
    "    overall_mean = df.iloc[:, :-1].mean()\n",
    "    overall_variance = df.iloc[:, :-1].var()\n",
    "\n",
    "    # Calculate inter-class variance\n",
    "    inter_class_variance = (class_variances * (grouped.size())).sum()\n",
    "\n",
    "    # Calculate intra-class variance\n",
    "    intra_class_variance = (grouped.size() * (class_means - overall_mean) ** 2).sum()\n",
    "\n",
    "    print(\"Inter-Class Variance:\", inter_class_variance)\n",
    "    print(\"Intra-Class Variance:\", intra_class_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Silhouette(df):\n",
    "    # Separate features and labels\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "\n",
    "    # Convert labels to numerical values\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    silhouette_avg = silhouette_score(X, y_encoded)\n",
    "    print(f\"Silhouette Score: {silhouette_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/9y3l_5550cq48b8gk93vt9p00000gn/T/ipykernel_33612/2132779695.py:66: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  dataset = dataset.groupby(stratify_by, group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Total samples in dataset: 201042 ***\n",
      "*** Samples for Chime_Doorbell: 11169 (0.05555555555555555%) ***\n",
      "*** Samples for D-Link_Cam936L: 11169 (0.05555555555555555%) ***\n",
      "*** Samples for Gosuna_LightBulb: 11169 (0.05555555555555555%) ***\n",
      "*** Samples for Gosuna_Socket: 11169 (0.05555555555555555%) ***\n",
      "*** Samples for Goumia_Coffemaker: 11169 (0.05555555555555555%) ***\n",
      "*** Samples for LaCrosse_AlarmClock: 11169 (0.05555555555555555%) ***\n",
      "*** Samples for Lumiman_Bulb600: 11169 (0.05555555555555555%) ***\n",
      "*** Samples for Lumiman_Bulb900: 11169 (0.05555555555555555%) ***\n",
      "*** Samples for Lumiman_SmartPlug: 11169 (0.05555555555555555%) ***\n",
      "*** Samples for Minger_LightStrip: 11169 (0.05555555555555555%) ***\n",
      "*** Samples for Ocean_Radio: 11169 (0.05555555555555555%) ***\n",
      "*** Samples for Renpho_SmartPlug: 11169 (0.05555555555555555%) ***\n",
      "*** Samples for Smart_Lamp: 11169 (0.05555555555555555%) ***\n",
      "*** Samples for Smart_LightStrip: 11169 (0.05555555555555555%) ***\n",
      "*** Samples for Tenvis_Cam: 11169 (0.05555555555555555%) ***\n",
      "*** Samples for Wans_Cam: 11169 (0.05555555555555555%) ***\n",
      "*** Samples for itTiot_Cam: 11169 (0.05555555555555555%) ***\n",
      "*** Samples for oossxx_SmartPlug: 11169 (0.05555555555555555%) ***\n"
     ]
    }
   ],
   "source": [
    "# Get the path to the CSV file\n",
    "# csv_file_path = input(\"Enter the path to the CSV file: \")\n",
    "# csv_file_path = \"/storage/nate/SmartRecon/FlexHash/similar_devices_Hashes/cam_allwinner_cleaned/cam_allwinner-1_128_4_2.csv\"\n",
    "\n",
    "# path_to_root_folder = (\n",
    "#     \"/Downloads/Nilsimsa/different_devices/\"\n",
    "# )\n",
    "# root_device = \"devices/\"\n",
    "\n",
    "# accumulator = 128\n",
    "# window = 6\n",
    "# combo = 6\n",
    "# device_list = list(range(1, 9))\n",
    "\n",
    "stratify_by = \"Label\"\n",
    "\n",
    "# csv_column_names = [f\"dim{i}\" for i in range(accumulator // 8)]\n",
    "# csv_column_names.append(stratify_by)\n",
    "\n",
    "# all_files = os.listdir(path_to_root_folder + root_device)\n",
    "# files_to_use = []\n",
    "# for file in all_files:\n",
    "#     if f\"{accumulator}_{window}_{combo}\" in file:\n",
    "#         files_to_use.append(path_to_root_folder + root_device + file)\n",
    "\n",
    "# dataset = combine_csv(files_to_use, csv_column_names)\n",
    "# dataset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dataset = pd.read_csv(\"~/Downloads/Nilsimsa/different_devices/devices/cleaned/batyr_modified_devices.csv\", header=None)\n",
    "dataset = dataset.set_axis(list(range(len(dataset.columns)-1)) + [\"Label\"], axis=1)\n",
    "\n",
    "#######\n",
    "# Define the sampling ratio\n",
    "# sampling_ratio = 0.1\n",
    "sampling_ratio = \"minimum\"\n",
    "# sampling_ratio = \"SelectMaxN\"\n",
    "\n",
    "if sampling_ratio == \"minimum\":\n",
    "    min_count = float(\"inf\")\n",
    "    for unique_class in dataset[stratify_by].unique():\n",
    "        unique_class_sample_count = dataset[dataset[stratify_by] == unique_class].shape[\n",
    "            0\n",
    "        ]\n",
    "        if unique_class_sample_count < min_count:\n",
    "            min_count = unique_class_sample_count\n",
    "    sample_sizes = (\n",
    "        dataset[stratify_by].value_counts().apply(lambda x: min(x, min_count))\n",
    "    ).astype(int)\n",
    "    # cams\n",
    "    # sample_sizes = sample_sizes // 10\n",
    "    # sample_sizes = sample_sizes // 50\n",
    "    # plugs\n",
    "    # sample_sizes = sample_sizes // 7\n",
    "\n",
    "elif sampling_ratio == \"SelectMaxN\":\n",
    "    MaxN = 2000\n",
    "    # Calculate the number of samples to take from each category\n",
    "    sample_sizes = (\n",
    "        dataset[stratify_by].value_counts().apply(lambda count: min(MaxN, count))\n",
    "    )\n",
    "else:\n",
    "    # Calculate the number of samples to take from each category\n",
    "    sample_sizes = (dataset[stratify_by].value_counts() * sampling_ratio).astype(int)\n",
    "\n",
    "# Perform stratified sampling\n",
    "dataset = dataset.groupby(stratify_by, group_keys=False).apply(\n",
    "    lambda x: x.sample(sample_sizes.loc[x.name], random_state=42)\n",
    ")\n",
    "# Reset the index if desired\n",
    "dataset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# device_names = dataset[stratify_by].str.split(\"_\").str[0]\n",
    "# device_numbers = dataset[stratify_by].str.split(\"-\").str[-1]\n",
    "# cams\n",
    "# dataset[stratify_by] = device_names + \"-\" + device_numbers\n",
    "# lights and plugs\n",
    "# dataset[stratify_by] = device_names\n",
    "\n",
    "print(f\"*** Total samples in dataset: {len(dataset.index)} ***\")\n",
    "for device_name in sorted(dataset[stratify_by].unique()):\n",
    "    num_samples = len((dataset[dataset[stratify_by] == device_name]).index)\n",
    "    # print(\n",
    "    #     f\"*** Samples for device: {device_name} in {accumulator}_{window}_{combo}: {num_samples} ({num_samples/dataset.shape[0]}%) ***\"\n",
    "    # )\n",
    "    print(\n",
    "        f\"*** Samples for {device_name}: {num_samples} ({num_samples/dataset.shape[0]}%) ***\"\n",
    "    )\n",
    "#######\n",
    "\n",
    "# Extract features and labels\n",
    "features = dataset.iloc[:, :-1].values\n",
    "labels = dataset.iloc[:, -1].values\n",
    "\n",
    "# inter_intra_class_var(dataset)\n",
    "# Silhouette(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize UMAP model with 2 components for 2D representation\n",
    "n_neighbors = 25\n",
    "min_dist = 1.0\n",
    "metric = \"canberra\"\n",
    "umap_model = umap.UMAP(\n",
    "    n_components=2, n_neighbors=n_neighbors, min_dist=min_dist, metric=metric\n",
    ")\n",
    "\n",
    "# Transform data using UMAP\n",
    "umap_result = umap_model.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for the transformed data\n",
    "umap_df = pd.DataFrame(umap_result, columns=[\"UMAP1\", \"UMAP2\"])\n",
    "\n",
    "umap_df[\"Label\"] = labels\n",
    "# inter_intra_class_var(umap_df)\n",
    "# Silhouette(umap_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "s = 10\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 10))\n",
    "# sns.set_theme()\n",
    "# plt.rcParams['axes.facecolor']='darkgray'\n",
    "sns.scatterplot(\n",
    "    data=umap_df,\n",
    "    x=\"UMAP1\",\n",
    "    y=\"UMAP2\",\n",
    "    hue=\"Label\",\n",
    "    palette=\"Paired\",\n",
    "    edgecolor=None,\n",
    "    s=s,\n",
    ")\n",
    "# plt.title(\"UMAP Visualization of Dataset\")\n",
    "plt.rcParams.update({\"font.size\": 16})\n",
    "\n",
    "font = font_manager.FontProperties(weight=\"bold\", size=18)\n",
    "plt.legend(prop=font, loc=\"upper left\")\n",
    "# plt.legend(prop=font, bbox_to_anchor=(.8, 1), loc='upper left')\n",
    "# plt.legend(title=\"Device\", fontsize=16, weight=\"bold\")\n",
    "\n",
    "plt.grid(False)\n",
    "# plt.xlabel('UMAP 1', fontsize=20)\n",
    "# plt.ylabel('UMAP 2', fontsize=20)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "# plt.show()\n",
    "print(\n",
    "    f\"Saved to: UMAP_visualizations/{root_device[:-1]}_{accumulator}_{window}_{combo}_{sampling_ratio}-{n_neighbors}-{min_dist}-{metric}-{s}.pdf\"\n",
    ")\n",
    "plt.savefig(\n",
    "    f\"UMAP_visualizations/{root_device[:-1]}_{accumulator}_{window}_{combo}_{sampling_ratio}-{n_neighbors}-{min_dist}-{metric}-{s}.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "s = 10\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 10))\n",
    "# sns.set_theme()\n",
    "# plt.rcParams['axes.facecolor']='darkgray'\n",
    "sns.scatterplot(\n",
    "    data=umap_df,\n",
    "    x=\"UMAP1\",\n",
    "    y=\"UMAP2\",\n",
    "    palette=\"cubehelix\",\n",
    "    hue=\"Label\",\n",
    "    edgecolor=None,\n",
    "    s=s,\n",
    ")\n",
    "# plt.title(\"UMAP Visualization of Dataset\")\n",
    "plt.rcParams.update({\"font.size\": 16})\n",
    "\n",
    "font = font_manager.FontProperties(weight=\"bold\", size=16)\n",
    "plt.legend(prop=font)\n",
    "# plt.legend(title=\"Device\", fontsize=16, weight=\"bold\")\n",
    "\n",
    "plt.grid(False)\n",
    "# plt.xlabel('UMAP 1', fontsize=20)\n",
    "# plt.ylabel('UMAP 2', fontsize=20)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "# plt.show()\n",
    "plt.savefig(\n",
    "    f\"UMAP_visualizations/{root_device[:-1]}_{accumulator}_{window}_{combo}_{sampling_ratio}-{n_neighbors}-{min_dist}-{metric}-{s}.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SmartRecon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
